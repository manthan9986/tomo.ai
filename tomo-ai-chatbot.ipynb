{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help summarize a document for you. Before we get started, can you please tell me a bit more about the PDF? For example, how many pages does it have, and what's the general topic or subject matter? Additionally, are you looking for a brief summary of the entire document, or would you like me to focus on specific sections or key takeaways?\n",
      "\n",
      "Also, I'll let you know that I'm trained on a vast amount of text data, but I don't have the capability to directly upload or access files. So, if you could copy and paste the text from the PDF or provide a link to a publicly accessible version, I'll do my best to assist you with the summary.\n",
      "I'd be happy to help write some code for you. Before we get started, can you please tell me a bit more about what you need? For example, what programming language are you interested in using (e.g., Python, Java, JavaScript, etc.)? Additionally, what kind of code are you trying to write (e.g., a simple script, a web application, a machine learning model, etc.)? Are there any specific requirements or constraints that the code should follow?\n",
      "\n",
      "Also, I can generate code snippets based on your requirements, but I'll need more details to ensure that the code meets your needs. If you have any existing code or examples that you've tried so far, please feel free to share those as well. This will help me better understand what you're trying to accomplish.\n",
      "\n",
      "Lastly, please keep in mind that I'm a large language model, I can generate code, but I'm not a compiler or an IDE, so I won't be able to execute or run the code for you.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\",api_key=\"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\")\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation_chain = ConversationChain(memory=memory,llm=llm)\n",
    "\n",
    "response = conversation_chain.run(input=\"can u summarize a pdf if i gave u my pdf  \")\n",
    "response2 = conversation_chain.run(input=\"can u write a code for me \")\n",
    "print(response)\n",
    "print(response2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
